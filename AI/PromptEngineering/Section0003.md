# How does AI work?


## => What are Tokens?
* **Examine token limits what are and how to gracefully handle limits.**

* What is Tokenization
    * Sentences, words and characters are transformed into lots of individual tokens.


![alt text](image-31.png)


* Token Limits
    * Restricted by the models that we choose to use.
    * Each model has an input token limit and and output token limit.

![alt text](image-32.png)

## How to get the token limit for ChatGPT and GPT-X

https://platform.openai.com/tokenizer

![alt text](image-33.png)

* How to get the token limit - Tokenizer
* Using python code

![alt text](image-34.png)



## Approaches to Avoid Hitting token limits

![alt text](image-30.png)


## Chat Models vs Reasoning Models

## AI Hallucinations

